{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Wood_Training.npy', allow_pickle= True)\n",
    "data2 = np.load('Wood_Testing.npy', allow_pickle= True)\n",
    "\n",
    "data.shape, data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_spectral_curves(data, num_samples=2):\n",
    "    \n",
    "    # Randomly choose `num_samples` rows\n",
    "    random_indices = np.random.choice(data.shape[0], num_samples, replace=False)\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Extract the spectral values (excluding the label)\n",
    "        spectral_values = data[idx, :-1]\n",
    "\n",
    "        # Extract the label (last column)\n",
    "        label = data[idx, -1]\n",
    "\n",
    "        # Create the x-axis for wavelength index (1 to 300)\n",
    "        wavelengths = np.arange(1, spectral_values.shape[0] + 1)\n",
    "\n",
    "        # Plot the spectral curve\n",
    "        plt.plot(wavelengths, spectral_values, label=f\"Sample {idx} - Label: {label}\")\n",
    "\n",
    "\n",
    "    plt.title(f\"Spectral Curves for {num_samples} Random Samples\")\n",
    "    plt.xlabel(\"Bands\")\n",
    "    plt.ylabel(\"Mean Reflectance\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_random_spectral_curves(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:, :-1]\n",
    "y_train = data[:, -1]  \n",
    "\n",
    "X_test = data2[:, :-1]\n",
    "y_test = data2[:, -1]  \n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_test)\n",
    "\n",
    "X_test = scaler2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    'n_neighbors': [3, 5],  # Use fewer values to test\n",
    "    'weights': ['uniform'],  # Try with just one weight for now\n",
    "    'metric': ['euclidean']  # Test one distance metric at a time\n",
    "}\n",
    "\n",
    "# KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_knn = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Training\n",
    "grid_search_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Accuracy\n",
    "y_test_pred = grid_search_knn.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(y_test_pred == y_test) * 100\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "le= LabelEncoder()\n",
    "y_train_encoded= le.fit_transform(y_train)\n",
    "\n",
    "le2= LabelEncoder()\n",
    "y_test_encoded= le2.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(y_train)\n",
    "print(unique_classes)\n",
    "\n",
    "unique_classes_encoded = np.unique(y_train_encoded)\n",
    "print(unique_classes_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "\n",
    "# GridSearchCV for XGBoost Classifier\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "xgb_grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get best parameters for XGBoost Classifier\n",
    "best_params = xgb_grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'C': [0.1, 1, 10, 100],         \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  \n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4, 5], \n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0] \n",
    "    \n",
    "}\n",
    "# SVM classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Instantiate the grid search\n",
    "random_search = RandomizedSearchCV(svc, param_distributions=param_dist, n_iter=10, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Training\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best parameters found by RandomizedSearchCV\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n",
    "# Use the best model to predict on the test data\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Accuracy\n",
    "y_test_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(y_test_pred == y_test) * 100\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(gpu_options =\n",
    "                         tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    ")\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(320,)),\n",
    "        Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01), name='layer1'),\n",
    "        #Dense(units=16, activation='relu', kernel_regularizer=regularizers.l2(0.001), name='layer2'),\n",
    "        #Dense(units=8, activation='relu', kernel_regularizer=regularizers.l2(0.0001), name='layer3'),\n",
    "        \n",
    "        Dense(units=2, activation='linear')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Training\n",
    "\n",
    "model.compile(\n",
    "    \n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-2),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    \n",
    "    X_train,y_train_encoded,\n",
    "    batch_size = 500,\n",
    "    epochs = 1000,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor = 'loss',\n",
    "            patience = 500,\n",
    "            restore_best_weights = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "#Accuracy\n",
    "# Calculate total accuracy\n",
    "total_accuracy = accuracy_score(y_test_encoded, predicted_labels)\n",
    "\n",
    "print(f\"Total Test Accuracy: {total_accuracy*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
